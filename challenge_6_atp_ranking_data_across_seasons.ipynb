{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicolasrojasv/nicolasrojasv.github.io/blob/main/challenge_6_atp_ranking_data_across_seasons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df2ab82a"
      },
      "source": [
        "# Retrieving Tennis player data from the ATP website across seasons\n",
        "Extract, clean, and save the ATP tennis player ranking data for the last December dates of 2024, 2020, 2016, 2012, 2008, and 2004 from the ATP website into separate JSON files, with each file named `atp_ranking_YYYY.json`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42353c39"
      },
      "source": [
        "#Load libraries\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import datetime\n",
        "from io import StringIO"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting the table with all ATP profesional players.\n",
        "url = \"https://www.atptour.com/en/rankings/singles?rankRange=0-5000&region=all&dateWeek=2025-12-15&SortField=null&SortAscending=null\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "html_content = response.text\n",
        "soup = BeautifulSoup(html_content, 'html.parser')"
      ],
      "metadata": {
        "id": "kl9BkgaArchV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the dates with available ranking data\n",
        "ranking_weeks = soup.find_all('select', id = \"dateWeek-filter\")"
      ],
      "metadata": {
        "id": "CrVvFFUgLKDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ebc1630",
        "outputId": "420a853c-08a9-4997-d40e-ba2c56ccd512"
      },
      "source": [
        "# Get only the date value\n",
        "ranking_values_initial = []\n",
        "for select_tag in ranking_weeks:\n",
        "    for option_tag in select_tag.find_all('option'):\n",
        "        ranking_values_initial.append(option_tag.get('value'))\n",
        "\n",
        "#Keep dates with year > 1999\n",
        "filtered_ranking_values = []\n",
        "for value in ranking_values_initial:\n",
        "    if value == 'Current Week':\n",
        "        continue\n",
        "    try:\n",
        "        date_obj = datetime.datetime.strptime(value, '%Y-%m-%d')\n",
        "        if date_obj.year > 1999:\n",
        "            filtered_ranking_values.append(value)\n",
        "    except ValueError:\n",
        "        pass\n",
        "\n",
        "# Keep only the last December date for each year\n",
        "last_december_dates = {}\n",
        "for value in filtered_ranking_values:\n",
        "    date_obj = datetime.datetime.strptime(value, '%Y-%m-%d')\n",
        "    if date_obj.month == 12:\n",
        "        year = date_obj.year\n",
        "        # Keep the latest December date for each year\n",
        "        if year not in last_december_dates or date_obj > last_december_dates[year]:\n",
        "            last_december_dates[year] = date_obj\n",
        "\n",
        "# Convert the dictionary values back to string format and sort them in descending order\n",
        "ranking_values = sorted([date_obj.strftime('%Y-%m-%d') for date_obj in last_december_dates.values()], reverse=True)\n",
        "\n",
        "print(\"Last December dates for each year (after 1999):\")\n",
        "for date in ranking_values:\n",
        "    print(date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last December dates for each year (after 1999):\n",
            "2025-12-22\n",
            "2024-12-30\n",
            "2023-12-25\n",
            "2022-12-26\n",
            "2021-12-27\n",
            "2020-12-28\n",
            "2019-12-30\n",
            "2018-12-31\n",
            "2017-12-25\n",
            "2016-12-26\n",
            "2015-12-28\n",
            "2014-12-29\n",
            "2013-12-30\n",
            "2012-12-31\n",
            "2011-12-26\n",
            "2010-12-27\n",
            "2009-12-28\n",
            "2008-12-29\n",
            "2007-12-31\n",
            "2006-12-25\n",
            "2005-12-26\n",
            "2004-12-27\n",
            "2003-12-29\n",
            "2002-12-30\n",
            "2001-12-31\n",
            "2000-12-25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfea78da",
        "outputId": "ce26a409-62c1-4ebb-e7a6-561fa15ff395"
      },
      "source": [
        "#Filter the 'ranking_values' list to include only the last December dates for the years 2024, 2020, 2016, 2012, 2008, and 2004.\n",
        "target_years = [2024, 2020, 2016, 2012, 2008, 2004]\n",
        "filtered_ranking_values_for_target_years = []\n",
        "\n",
        "for date_string in ranking_values:\n",
        "    year = int(date_string[:4])\n",
        "    if year in target_years:\n",
        "        filtered_ranking_values_for_target_years.append(date_string)\n",
        "\n",
        "print(\"Filtered ranking values for target years:\")\n",
        "for date in filtered_ranking_values_for_target_years:\n",
        "    print(date)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered ranking values for target years:\n",
            "2024-12-30\n",
            "2020-12-28\n",
            "2016-12-26\n",
            "2012-12-31\n",
            "2008-12-29\n",
            "2004-12-27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bce50bf",
        "outputId": "eebb94bd-f930-41f4-ffb2-549bfda7b16f"
      },
      "source": [
        "#This loop iterate through the filtered dates, fetch the ranking data for each year, clean it, and save it as a separate JSON file.\n",
        "for date_to_process in filtered_ranking_values_for_target_years:\n",
        "    year = date_to_process[:4]\n",
        "    print(f\"Processing data for year: {year} and date: {date_to_process}\")\n",
        "\n",
        "    # Construct the URL for the current date\n",
        "    url = f\"https://www.atptour.com/en/rankings/singles?rankRange=0-5000&region=all&dateWeek={date_to_process}&SortField=null&SortAscending=null\"\n",
        "\n",
        "    # Make the request and parse the HTML\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Extract the table into a DataFrame, now using StringIO for future compatibility\n",
        "    dfs_tables = pd.read_html(StringIO(html_content))\n",
        "    player_data = dfs_tables[1]\n",
        "\n",
        "    # Clean the DataFrame (reusing cleaning logic of challenge 5)\n",
        "    player_data_clean = player_data[[\"Hidden header\", \"Player\", \"Age\", \"Official Points\", \"Tourn Played\"]]\n",
        "    player_data_clean = player_data_clean.rename(columns={\n",
        "        \"Hidden header\": \"rank\",\n",
        "        \"Player\": \"player_name\",\n",
        "        \"Age\": \"age\",\n",
        "        \"Official Points\": \"points\",\n",
        "        \"Tourn Played\": \"n_tournaments\"\n",
        "    })\n",
        "\n",
        "    # Clean player names\n",
        "    player_data_clean['player_name'] = player_data_clean['player_name'].str.replace(r'^[-\\d\\s]+', '', regex=True)\n",
        "\n",
        "    # Remove the problematic row (index 10) if it exists after cleaning\n",
        "    # It's safer to check for the content rather than fixed index due to potential data variations\n",
        "    if 10 in player_data_clean.index and \"googletag.cmd.push\" in player_data_clean.loc[10, 'player_name']:\n",
        "        player_data_clean = player_data_clean.drop(index=10)\n",
        "\n",
        "    # Convert 'points' to numeric\n",
        "    player_data_clean['points'] = pd.to_numeric(player_data_clean['points'], errors='coerce')\n",
        "\n",
        "    # Calculate the difference between player rank 3 and the rest.\n",
        "    points_rank_three = player_data_clean.loc[2, 'points']\n",
        "    player_data_clean[\"diff_rank_three\"] = abs(player_data_clean[\"points\"] - points_rank_three)\n",
        "\n",
        "    # Column with the last name\n",
        "    player_data_clean['last_name'] = player_data_clean['player_name'].apply(lambda x: x.split(' ', 1)[1] if len(x.split(' ', 1)) > 1 else '')\n",
        "\n",
        "    # Pass data to number\n",
        "    player_data_clean['rank'] = player_data_clean['rank'].astype(str).str.replace('T', '', regex=False)\n",
        "    player_data_clean['rank'] = pd.to_numeric(player_data_clean['rank'], errors='coerce')\n",
        "    player_data_clean['age'] = pd.to_numeric(player_data_clean['age'], errors='coerce')\n",
        "    player_data_clean['n_tournaments'] = pd.to_numeric(player_data_clean['n_tournaments'], errors='coerce')\n",
        "\n",
        "    # Save the cleaned data to a JSON file\n",
        "    save_path = f'atp_ranking_{year}.json'\n",
        "    player_data_clean.to_json(save_path, orient='records', indent=4)\n",
        "    print(f\"Saved data for {year} to {save_path}\")\n",
        "\n",
        "    # Add a small delay to avoid overwhelming the server\n",
        "    time.sleep(1)\n",
        "\n",
        "print(\"Data extraction and saving complete for all target years.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing data for year: 2024 and date: 2024-12-30\n",
            "Saved data for 2024 to atp_ranking_2024.json\n",
            "Processing data for year: 2020 and date: 2020-12-28\n",
            "Saved data for 2020 to atp_ranking_2020.json\n",
            "Processing data for year: 2016 and date: 2016-12-26\n",
            "Saved data for 2016 to atp_ranking_2016.json\n",
            "Processing data for year: 2012 and date: 2012-12-31\n",
            "Saved data for 2012 to atp_ranking_2012.json\n",
            "Processing data for year: 2008 and date: 2008-12-29\n",
            "Saved data for 2008 to atp_ranking_2008.json\n",
            "Processing data for year: 2004 and date: 2004-12-27\n",
            "Saved data for 2004 to atp_ranking_2004.json\n",
            "Data extraction and saving complete for all target years.\n"
          ]
        }
      ]
    }
  ]
}